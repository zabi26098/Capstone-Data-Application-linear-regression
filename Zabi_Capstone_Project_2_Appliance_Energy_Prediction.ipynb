{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lplIw_pwndR"
   },
   "source": [
    "## **Project Name    -Appliance Energy Prediction**    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8JqCAwqx-qw"
   },
   "source": [
    "##### **Project Type**    - Regression\n",
    "##### **Contribution**    - Team\n",
    "##### **Team Member 1 -Mohammad zabi ur rahman**\n",
    "##### **Team Member 2 -Komal**\n",
    "##### **Team Member 3 -Mohd abdul samad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "226_2TP7eFEm"
   },
   "source": [
    "# **Project Summary -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPbYZwjNeI1d"
   },
   "source": [
    "The capstone project Appiance Energy Prediction is about performing analysis on the data of energy used by the appliances in watt per hour collected for every 10 min from January to May. \n",
    "\n",
    "Currently there is an uncontrollable damage to the environment because of rapid consumption of natural resources of Earth. The increase of C02 is\n",
    "rampant and the damage to the ozone layer is critical. The usage of\n",
    "appliances in daily households also are contributing to the damage of Earth\n",
    "and its environment. Tracking the usage and the amount of energy can be\n",
    "very useful in curbing the problems by keeping the usage in control. We are\n",
    "tasked with tracking the usage using supervised ML algorithms.\n",
    "\n",
    "This project contains a data set which comprises of 29 columns among which we have a dependent variable called Appliances and 28 independent variables. It has a column Date, Temperature values of different rooms of a building from T1 to T9 and Tout in celsius. It also contains Humidity values of different rooms of a building from RH1 to RH9 and RHout in % . It has other columns like Pressure , Windspeed, Visibility, Tdewpoint in respective units mm Hg, m/s , Km,Â°C. Most of the column values are of float data type.\n",
    "\n",
    "In this time of global uncertainty world needs energy and in increasing quantities to support economic and social progress and build a better quality of life, in particular in developing countries. But even in today’s time there are many places especially in developing world where there are outages. These outages are primary because of excess load consumed by appliances at home. Heating and cooling appliances takes most power in house. In this project we will be analysing the appliance usage in the house gathered via home sensors. All readings are taken at 10 mins intervals for 4.5 months . The goal is to predict energy consumption by appliances . In the age of smart homes, ability to predict energy consumption can not only save money for end user but can also help in generating money for user by giving excess energy back to Grid (in case of solar panels usage). In this case regression analysis will be used to predict Appliance energy usage based on data collected from various sensors.\n",
    "\n",
    "In this project we loaded the dataset and we started by\n",
    "extracting head and tail of the dataset to see the sample data and then came\n",
    "extracting info of the dataset which tells the type of data present in different columns, the next step was producing description of data and checking the unique count of column values.We also checked for null values and created dummies for data which aren't numeric.We plotted relevant graphs to extract information from them. We also detected outliers in columns using Boxplots and\n",
    "removed them.We also plotted correlation plots for numeric features to get additional information. We successfully performed EDA and produced conclusions on it. we also did feature engineering by creating a new variables called High cosumption and low consumption .First we created a Function called mean_energy_per_hour that takes the values of Appliance energy as input and calculates the mean of hour and Appliance values  .This segregates the values of Appliance Column into Low Consumption and High Consumption by taking the hour average of Appliance Usage as reference\n",
    "\n",
    "Then we implemented supervised machine learning model(Regression) on our cleaned data set.We calculated the Variation Inflation Factor(VIF) scores of all the columns and dropped the columns which had VIF score greater than 10. This really helped us in removing the collinearity of the columns and making it desirable for modelling. We used models like Linear Regression, Lasso Regression, Ridge Regression, Decision Trees, Random Forest, XGBoost ,Extra trees regression models. Random Forest, Extra Trees are the ensembles of decision trees. We evaluated these models on basis of R2 score ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HRdbppweJaX"
   },
   "source": [
    "# **GitHub Link** -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFGxlvK3AUWo"
   },
   "source": [
    " https://github.com/ZeeshanAhmed95/Capstone-Data-Application-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5SgGpexegIG"
   },
   "source": [
    "# **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt4KjyJxhb-K"
   },
   "source": [
    "Data-driven prediction of energy use of appliances\n",
    "The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions\n",
    "were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the\n",
    "temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for\n",
    "10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters.\n",
    "Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded\n",
    "from a public data set from Reliable Prognosis (rp5.ru) and merged together with the\n",
    "experimental data sets using the date and time column. Two random variables have been\n",
    "included in the data set for testing the regression models and to filter out non-predictive attributes\n",
    "(parameters).\n",
    "\n",
    "date time year-month-day hour:minute:second\n",
    "\n",
    "Appliances, energy use in Wh (Dependent variable)\n",
    "\n",
    "lights, energy use of light fixtures in the house in Wh (Drop this column)\n",
    "\n",
    "T1, Temperature in kitchen area, in Celsius\n",
    "\n",
    "RH1, Humidity in kitchen area, in % T2, Temperature in living room area, in Celsius\n",
    "\n",
    "RH2,Humidity in living room area, in %\n",
    "\n",
    "T3, Temperature in laundry room area\n",
    "\n",
    "RH3, Humidity in laundry room area, in % T4, Temperature in office room, in \n",
    "Celsius \n",
    "\n",
    "RH4,Humidity in office room, in %\n",
    "\n",
    "T5, Temperature in bathroom, in Celsius\n",
    "\n",
    "RH5, Humidity in bathroom, in % T6, Temperature outside the building (north side), in Celsius\n",
    "\n",
    "RH6, Humidity outside the building (north side), in %\n",
    "\n",
    "T7, Temperature in ironing room , in Celsius\n",
    "\n",
    "RH7, Humidity in ironing room, in % T8, Temperature in teenager room 2, in Celsius\n",
    "\n",
    "RH8,Humidity in teenager room 2, in %\n",
    "\n",
    "T9, Temperature in parents room, in Celsius\n",
    "\n",
    "RH9, Humidity in parents room, in % To, Temperature outside (from Chievres weather station), in Celsius\n",
    "\n",
    "Pressure (from Chievres weather station), in mm Hg RHout, Humidity outside (from\n",
    "Chievres weather station), in %\n",
    "\n",
    "Wind speed (from Chievres weather station), in m/s\n",
    "\n",
    "Visibility (from Chievres weather station), in km\n",
    "\n",
    "Tdewpoint (from Chievres weather station), Â°C\n",
    "\n",
    "rv1, Random variable 1, nondimensional\n",
    "\n",
    "rv2, Random variable 2, nondimensional\n",
    "\n",
    "Where indicated, hourly data (then interpolated) from the nearest airport weather station(Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis,rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of\n",
    "weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edBSg7pjk0sd"
   },
   "source": [
    "##  **Know Your Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E30Hks_Lk4fL"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlml07T6XIyz"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import math\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import matplotlib.pyplot as plt                        # visualize with plots\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-white')\n",
    "import plotly.express as px  \n",
    "from datetime import datetime \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score, auc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgqE2YlGm9Id"
   },
   "source": [
    "# **DATA LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqBPFZsFXPLm"
   },
   "outputs": [],
   "source": [
    "# Importing Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt6YbsT-nAku"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6511iCVXQnv"
   },
   "outputs": [],
   "source": [
    "# Reading the dataset which is in csv.\n",
    "df = pd.read_csv('/content/drive/MyDrive/Almabetter /data_application_energy.csv',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRTmCQcGnkZl"
   },
   "source": [
    "# **DATA UNDERSTANDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TqWbMrHnE8o"
   },
   "source": [
    "### Dataset First View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwTh2jkxXmxV"
   },
   "outputs": [],
   "source": [
    "#Visualizing the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KR4nGELS6LxL"
   },
   "outputs": [],
   "source": [
    "# extracting tail of the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb62vtOknIzE"
   },
   "source": [
    "### Dataset Rows & Columns count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urTDyJT9X2kk"
   },
   "outputs": [],
   "source": [
    "#The shape of the dataset i.e, number of rows and columns   \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6ZU_ZE5nT4r"
   },
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skiElLuvXpel"
   },
   "outputs": [],
   "source": [
    "#Checking the datatype of the column values and non-null count\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsAeSC2lnZ9-"
   },
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCHGaE5KoO0W"
   },
   "outputs": [],
   "source": [
    "# getting duplicates\n",
    "Dublicates=df[df.duplicated()]\n",
    "print(f'The Dublicate Values in Dataframe: ')\n",
    "Dublicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMi8YHl_oZ7b"
   },
   "source": [
    "### There are no duplicates in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15uRg6wToib8"
   },
   "source": [
    "# **DATA CLEAN UP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x46xgeVaooFW"
   },
   "source": [
    "## Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKMKMCtcZUXm"
   },
   "outputs": [],
   "source": [
    "#Checking if there are null values or not and their sum for each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRqn7p4NZ3hb"
   },
   "source": [
    "#### This result shows there are no null values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muIc4RpQpJEr"
   },
   "source": [
    "### What did you know about your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10UKxUe-pKJU"
   },
   "source": [
    "We got to know that Appliances column is the dependent variable in the dataset. The values of the Appliances column is in integer datatype and is in Watt per hour. Most of the datatypes of the columns in the dataset are of float. The dataset contain 31 independent variables and 19735 rows of observations recorded every 10 minutes starting from 17th hour of January 11 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqbJbU_MpaXr"
   },
   "source": [
    "## *** Understanding Your Variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXaNNXdIXpg5"
   },
   "outputs": [],
   "source": [
    "#Checking the names of all columns of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OK6M90B-XpcN"
   },
   "outputs": [],
   "source": [
    "#Checking the description of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYer8cwOpliL"
   },
   "source": [
    "### Variables Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-4xjbTFp-pl"
   },
   "source": [
    "date : time year-month-day hour:minute:second\n",
    "\n",
    "Appliances : energy use in Wh (Dependent variable)\n",
    "\n",
    "lights : energy use of light fixtures in the house in Wh (Drop this column)\n",
    "\n",
    "T1 : Temperature in kitchen area, in Celsius\n",
    "\n",
    "RH1 : Humidity in kitchen area, in %\n",
    "\n",
    "T2 : Temperature in living room area, in Celsius\n",
    "\n",
    "RH2 : Humidity in living room area, in %\n",
    "\n",
    "T3 : Temperature in laundry room area\n",
    "\n",
    "RH3 : Humidity in laundry room area, in % \n",
    "\n",
    "T4 : Temperature in office room, in Celsius \n",
    "\n",
    "RH4 : Humidity in office room, in %\n",
    "\n",
    "T5 : Temperature in bathroom, in Celsius\n",
    "\n",
    "RH5: Humidity in bathroom, in % \n",
    "\n",
    "T6 : Temperature outside the building (north side), in Celsius\n",
    "\n",
    "RH6 : Humidity outside the building (north side), in %\n",
    "\n",
    "T7 : Temperature in ironing room , in Celsius\n",
    "\n",
    "RH7 : Humidity in ironing room, in %\n",
    "\n",
    "T8 : Temperature in teenager room 2, in Celsius\n",
    "\n",
    "RH8 : Humidity in teenager room 2, in %\n",
    "\n",
    "T9 : Temperature in parents room, in Celsius\n",
    "\n",
    "RH9 : Humidity in parents room, in % \n",
    "\n",
    "To : Temperature outside (from Chievres weather station), in Celsius\n",
    "\n",
    "Pressure : (from Chievres weather station), in mm Hg\n",
    "\n",
    "RHout : Humidity outside (from Chievres weather station),in %\n",
    "\n",
    "Wind speed : (from Chievres weather station), in m/s\n",
    "\n",
    "Visibility : (from Chievres weather station), in km\n",
    "\n",
    "Tdewpoint : (from Chievres weather station), Â°C\n",
    "\n",
    "rv1 : Random variable 1, nondimensional\n",
    "\n",
    "rv2 : Random variable 2, nondimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2h4SzCbsH6c"
   },
   "source": [
    "### Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Cw3E0KLsYpV"
   },
   "outputs": [],
   "source": [
    "# getting number of unique values for each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieh86hNqXi_5"
   },
   "source": [
    "##       **FeatureEngineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38gZ_AyKXe7G"
   },
   "outputs": [],
   "source": [
    "#Extracting the months, hours and weeks from the date column by setting it as index\n",
    "df = df.set_index('date')\n",
    "df['month'] = df.index.month\n",
    "df['hour'] = df.index.hour\n",
    "df['week'] = df.index.week\n",
    "df['weekday'] = df.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgFvc8xoXiMF"
   },
   "outputs": [],
   "source": [
    "# Resetting the index and the date returns back to being a column\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INiY_LQFZeyr"
   },
   "outputs": [],
   "source": [
    "# Creating a new feature\n",
    "# Calculate average energy load per hour\n",
    "def mean_energy_per_hour(df, hour_feature, energy_feature):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where keys are unique categories of the cat_feature,\n",
    "    and values are means over real_feature\n",
    "    \"\"\"\n",
    "    return dict(df.groupby(hour_feature)[energy_feature].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnyUApGXZlCV"
   },
   "outputs": [],
   "source": [
    "df['hour_avg'] = list(map(mean_energy_per_hour(df[:], 'hour', \"Appliances\").get, df.hour)) #Calculating amount energy used per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDoUjDdoZmco"
   },
   "outputs": [],
   "source": [
    "# categorizing them as low and high according their values\n",
    "df['low_consum'] = (df.Appliances+25<(df.hour_avg))*1\n",
    "df['high_consum'] = (df.Appliances+100>(df.hour_avg))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOEflzFVjFpL"
   },
   "source": [
    "***We assume that we have low(high) energy load when the appliances consumption is lower(higher) than a given point of the hourly average counsumption. This point is dependent of date time frequency and the numbers below are set after several tryouts based on appliances' consumption standard deviation.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chZXg3TPanFR"
   },
   "outputs": [],
   "source": [
    "#Making a copy of the original dataset for furthur analysis\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJzBFF0XZvDC"
   },
   "outputs": [],
   "source": [
    "#Converting month number to month name\n",
    "import calendar\n",
    "df1['month'] = df1['month'].apply(lambda x: calendar.month_abbr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TlNNfeqZya1"
   },
   "outputs": [],
   "source": [
    "# Average energy consumption per weekday and hour\n",
    "df['weekday_avg'] = list(map(\n",
    "    mean_energy_per_hour(df[:], 'weekday', \"Appliances\").get, df.weekday))\n",
    "df['hour_avg'] = list(map(\n",
    "    mean_energy_per_hour(df[:], 'hour', \"Appliances\").get, df.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj0qjNzFaDwM"
   },
   "outputs": [],
   "source": [
    "#Extracting the year from the date column\n",
    "year = []\n",
    "for i in range(len(df['date'])):\n",
    "  year.append(df['date'][i].year)\n",
    "df['year'] = year  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63QQS3s0aHI3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find outliers\n",
    "sorted_appliances = df1.sort_values('Appliances',ascending=False)\n",
    "print(\"The number of the 0,1% top values of appliances' load is\",\n",
    "      len(sorted_appliances.head(len(sorted_appliances)//1000)),\"and they have power load higher than\",\n",
    "      sorted_appliances.Appliances[19], \"Wh.\")\n",
    "\n",
    "# boxplot appliances\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(sorted_appliances.Appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUccDwakaJTI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Outliers removal\n",
    "\n",
    "df1 = df.dropna()\n",
    "df1 = df.drop(df[(df.Appliances>140)|(df.Appliances<0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBMSErMBaXIB"
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a4V2SWLabKu"
   },
   "outputs": [],
   "source": [
    "# Dropping the month, week,year column as we are done with EDA\n",
    "df2.drop(columns = (['month', 'week', 'year']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLi-EsVdulqz"
   },
   "source": [
    "## What all manipulations have you done and insights you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxqPt3SVumdt"
   },
   "source": [
    "We extracted the month, hour and week values from the date column by setting the index of the dataset as date. Then we allocated these values in the new columns. \n",
    "\n",
    "We calculated the average of the all the energy used by the Appliances in a hour and then created a new feature hour_avg which has all the avg values of an hour in it. \n",
    "\n",
    "We created two new features called Low_Consum(Low consumption) and High_Consum(High Consumption). These columns have 0s and 1s in their values that imply if the hourly average energy used is less than Applainces+25 then its Low consumption and if the hourly average energy used is greater than Applainces+100 then its High consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ec0svZMAusk8"
   },
   "source": [
    "## *** Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vho2BSReu7du"
   },
   "source": [
    "## Chart - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Az8a9Kjq-w0J"
   },
   "outputs": [],
   "source": [
    "values = list(df['hour_avg'].unique())\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dy_7tfRCRj3V"
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(24):\n",
    "  names.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOIFar53Fw_7"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(25,8)})\n",
    "sns.barplot(x = names, y =  values, palette = 'hot_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL--my13vBEQ"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWxBXEecvA9f"
   },
   "source": [
    "BarPlot is a plot from matplotlib library which is similar to the countplot and is used to distinguish two values effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWWgV4movA18"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLE0aflGvdtE"
   },
   "source": [
    "The average energy usage is at its highest during the 18th hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPT6mwJPjitt"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQr9tiLSvpnP"
   },
   "source": [
    "The Energy is higher in certain hour of the day and it can fixed by being consicous about energy usage at that hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxIxbzP1vqAO"
   },
   "source": [
    "## Chart - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1bW_Ox6sPb_"
   },
   "source": [
    "###Checking the variations of temperatures among all the rooms of the building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILwEsG8vgWoF"
   },
   "outputs": [],
   "source": [
    "# assigning values to variables for plots\n",
    "T1 = df['T1'].values.mean()\n",
    "T2 = df['T2'].values.mean()\n",
    "T3 = df['T3'].values.mean()\n",
    "T4 = df['T4'].values.mean()\n",
    "T5 = df['T5'].values.mean()\n",
    "T7 = df['T7'].values.mean()\n",
    "T8 = df['T8'].values.mean()\n",
    "T9 = df['T9'].values.mean()\n",
    "# We have not included the temps T6 and T_out as they are the temps from outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4YAqE38hTQl"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Figure Size\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "values = [T1,T2,T3,T4,T5,T7,T8,T9]\n",
    "names = ['T1','T2','T3','T4','T5','T7','T8','T9']\n",
    "# Horizontal Bar Plot\n",
    "plt.bar(names, values)\n",
    " \n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "567P24uqAdTh"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJGjOVQ0AjWj"
   },
   "source": [
    "BarPlot is a plot from matplotlib library which is similar to the countplot and is used to distinguish two values effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGBRDHMOAjtj"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9bHXPCiAncA"
   },
   "source": [
    "#####The warmest temperatures are  laundry room(T3), teenager room(T8) and kitchen area(T1) respectively. And the coldest rooms are bathroom(T5) and parents room(T9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X_BTdO6hvdG"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtLNiDgaAI1J"
   },
   "source": [
    "The Temperatuure is proportional to Energy use so the rooms with higher temps should be controlled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgVUhkjcjvJb"
   },
   "source": [
    "# Checking the energy variations with respect to temperatures outside the building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjbsPy3QAwYf"
   },
   "source": [
    "## Chart - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dquGU-ozjCJ2"
   },
   "outputs": [],
   "source": [
    "# assigning values to variables for plots\n",
    "T6 = df['T6'].values\n",
    "T_out = df['T_out'].values\n",
    "Appliance_energy = df['Appliances'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NImQUfU0kAc6"
   },
   "outputs": [],
   "source": [
    "#scatter plot of Temperature vs Energy usage\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.gca()\n",
    "feature = df['T6']\n",
    "label = df['Appliances']\n",
    "correlation = feature.corr(label)\n",
    "plt.scatter(x=feature, y=label)\n",
    "plt.xlabel('T6')\n",
    "plt.ylabel('Energy usage in WH')\n",
    "ax.set_title('Appliances and' + ' T6' + '- correlation: ' + str(correlation))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXdQk4GpB6tj"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMd8A0iAB-w2"
   },
   "source": [
    "Scatter plots are used to plot data points on a horizontal and a vertical axis in the attempt to show how much one variable is affected by another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeCto7AUB-ts"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEDX8pmXCFD3"
   },
   "source": [
    "##### The correlation is minute but it exists between energy use and temperature northside of the building. The energy usage stays consistent from temperatures 5° to 25°. At extreme high and low temperatures, the energy usage is relatively low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM_-XYXTlXK3"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTgAgIqTCLEZ"
   },
   "source": [
    "This plot shows that the temperatures should be checked outside the building so Air Conditioners are used less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl5jYWyYCLlh"
   },
   "source": [
    "## Chart - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9UFbWUUq89T"
   },
   "outputs": [],
   "source": [
    "#scatter plot of Temperature vs Energy usage\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.gca()\n",
    "feature = df['T_out']\n",
    "label = df['Appliances']\n",
    "correlation = feature.corr(label)\n",
    "plt.scatter(x=feature, y=label)\n",
    "plt.xlabel('T_out')\n",
    "plt.ylabel('Appliances')\n",
    "ax.set_title('Appliances and' +' T_out' + '- correlation: ' + str(correlation))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtSEG8mXCa1j"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaQRmANSCb5X"
   },
   "source": [
    "Scatter plots are used to plot data points on a horizontal and a vertical axis in the attempt to show how much one variable is affected by another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlnTJr3vCanf"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4ypSchzCjzM"
   },
   "source": [
    "##### There is little correlation between temperatures in neighbourhood and energy usage. There is an acute drop at extreme highs and lows in temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk-FvHOCste-"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMuQ7AzECjqv"
   },
   "source": [
    "This plot shows that the temperatures should be checked outside the building so Air Conditioners are used less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DLPpIx6z3BE"
   },
   "source": [
    "# Variations in Energy consumption with respect to Pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtPIxaETCxqJ"
   },
   "source": [
    "## Chart - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-yHWyF3uiTS"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.gca()\n",
    "feature = df['Press_mm_hg']\n",
    "label = df['Appliances']\n",
    "correlation = feature.corr(label)\n",
    "plt.scatter(x=feature, y=label)\n",
    "plt.xlabel('Press_mm_hg')\n",
    "plt.ylabel('Appliances')\n",
    "ax.set_title('Appliances and' + ' Press_mm_hg' + '- correlation: ' + str(correlation))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_fvbuZsC-e4"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyzptxBcC-Zt"
   },
   "source": [
    "Scatter plots are used to plot data points on a horizontal and a vertical axis in the attempt to show how much one variable is affected by another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF1wLri6C-Un"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMz3ygZADJTp"
   },
   "source": [
    "##### There is little to  no correlation between pressure and energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WHEIHcv1CCv"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37X_tJ1dDJPo"
   },
   "source": [
    "The humidity values should not be kept in checked as there is no correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY5K_QBQ3aNN"
   },
   "source": [
    "# Energy variation with respect to humidity in different rooms of building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tnEvFrzDoFz"
   },
   "source": [
    "## Chart - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-mu4Cv8uiQt"
   },
   "outputs": [],
   "source": [
    "# assigning values to variables for plots\n",
    "RH1 = df['RH_1'].values.mean()\n",
    "RH2 = df['RH_2'].values.mean()\n",
    "RH3 = df['RH_3'].values.mean()\n",
    "RH4 = df['RH_4'].values.mean()\n",
    "RH5 = df['RH_5'].values.mean()\n",
    "RH6 = df['RH_6'].values.mean()\n",
    "RH7 = df['RH_7'].values.mean()\n",
    "RH8 = df['RH_8'].values.mean()\n",
    "RH9 = df['RH_9'].values.mean()\n",
    "RH_out = df['RH_out'].values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgjMo_hw4G9M"
   },
   "outputs": [],
   "source": [
    "# Figure Size\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "values = [RH1,RH2,RH3,RH4,RH5,RH6,RH7,RH8,RH9,RH_out]\n",
    "names = ['RH_1','RH_2','RH_3','RH_4','RH_5','RH_6','RH_7','RH_8','RH_9','RH_out']\n",
    "# Horizontal Bar Plot\n",
    "plt.bar(names, values)\n",
    " \n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeoIOwcoD0ci"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h9PMmr4D0UK"
   },
   "source": [
    "BarPlot is a plot from matplotlib library which is similar to the countplot and is used to distinguish two values effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l7pd5JAD0L9"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPPSm3xED_3j"
   },
   "source": [
    "##### The humidity is at its highest outside the building(RH_out) and lowest in the ironing room(RH_7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pU3qYkK74hwQ"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUBN5setD_tI"
   },
   "source": [
    "The highest is outside and the lower values should be increased so that enrgy used decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI7_4Ik6EKHh"
   },
   "source": [
    "## Chart - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2xd0wnH_e4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# obtaining correlation plots between humidity values and energy comsumption.\n",
    "for i in names:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = df[i]\n",
    "    label = df['Appliances']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label)\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Appliances')\n",
    "    ax.set_title('Appliances' + i + '- correlation: ' + str(correlation))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1lJc6isEXud"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qdSi4J5EXk3"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjV5tvw9EXaQ"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTQ4Nu89Nzpn"
   },
   "source": [
    "###All the scatterplots between humidity among different rooms of the building and energy cosumption:\n",
    "\n",
    "1.Humidity in kitchen area shows a normal distribution w.r.t energy consumption.Little to no consumption after humidity reaches >50.\n",
    "\n",
    "2.Very low energy consumption for humidity levels of 20 to 30 in the living room with sudden increase to adjacent levels of humidity.\n",
    "\n",
    "3.Humidty in laundry room influences the energy consumption similar to that of living room.\n",
    "\n",
    "4.Little to no contribution from humidity levels of office room towards energy consumption.\n",
    "\n",
    "5.No influence by humidity levels of bathroom towards energy consumption.\n",
    "\n",
    "6.Energy consumption may be inversely correlated to the humidity levels of northside outside of the building.\n",
    "\n",
    "7.Energy consumption is highly inversely correlated to  humidity levels of neighbourhood of the building.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pr2s66QEjuB"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE-9s0-WEi-6"
   },
   "source": [
    "The Energy use increases with decrease in the humidity values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgO7V_hoEpjP"
   },
   "source": [
    "## Chart - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnqBJu8Tbt2e"
   },
   "outputs": [],
   "source": [
    "df1['month'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwtdBC0WYlzL"
   },
   "source": [
    "# The data has been collected from months January to May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkJ70zb2Zy2k"
   },
   "outputs": [],
   "source": [
    "#Creating a dataframe with respect to the month column's sum\n",
    "df_month = df.groupby('month').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxLOXROvaKLE"
   },
   "outputs": [],
   "source": [
    "# Pie chart of dataframe of month versus Appliances column\n",
    "df_month['Appliances'].plot(kind='pie', subplots=True, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXgzQmgAFng3"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqrwW18vFnZp"
   },
   "source": [
    "Piechart is a chart from matplolib library which is really helpful in representing the values occupied by certain values in a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odCYoPvtFmuJ"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zdxeUQxFyuK"
   },
   "source": [
    "##### From this Pie chart we can observe that in Feb, Mar, April, the usage of appliances is more or less equal and that of Jan was the lowest one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhSbFKsLcmFj"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trMt4mYAF74R"
   },
   "source": [
    "The Janurary month has the lowest Energy use maybe because the temperature is lowest in that month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6KJTo7uF8T3"
   },
   "source": [
    "## Chart - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_9sBaYYyKaC"
   },
   "outputs": [],
   "source": [
    "# Functions to be used from the plots\n",
    "\n",
    "def daily(x,df=df1):\n",
    "    return df.groupby('weekday')[x].mean()\n",
    "def hourly(x,df=df):\n",
    "    return df.groupby('hour')[x].mean()\n",
    "\n",
    "def monthly_daily(x,df=df):\n",
    "    by_day = df.pivot_table(index='weekday', \n",
    "                                columns=['month'],\n",
    "                                values=x,\n",
    "                                aggfunc='mean')\n",
    "    return round(by_day, ndigits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iaff4jsMyK8c"
   },
   "outputs": [],
   "source": [
    "# Plot of Mean Energy Consumption per Day of Week\n",
    "\n",
    "daily('Appliances').plot(kind = 'bar', figsize=(10,8))\n",
    "ticks = list(range(0, 7, 1)) \n",
    "labels = \"Mon Tues Weds Thurs Fri Sat Sun\".split()\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Appliances consumption in Wh')\n",
    "plt.title('Mean Energy Consumption per Day of Week')\n",
    "plt.xticks(ticks, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6duY98wPHTOJ"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCiTzB6hHTEa"
   },
   "source": [
    "BarPlot is a plot from matplotlib library which is similar to the countplot and is used to distinguish two values effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gkh9HNU1HSys"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysnpM2xlHntg"
   },
   "source": [
    "##### Energy Usage was obeserved to be at its peak on Monday and it was it's lowest on Tuesday. There was high usage of Appliances on weekend i.e Friday, Saturday, Sunday than compared to weekdays. so, we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg6Mfv5fza6N"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBAdcURaHvWk"
   },
   "source": [
    "Monday is the busiest day of the week so it's a given that it will have the most energy used in a week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dorKZX54HvJ0"
   },
   "source": [
    "## Chart - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BXUWW7_aZd6"
   },
   "outputs": [],
   "source": [
    "#Checking if all the hours of a day are considered or not\n",
    "df['hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VlIJuQ5dHIG"
   },
   "outputs": [],
   "source": [
    "#Creating another dataframe with respect to the hour column's sum\n",
    "df_hourly = df.groupby('hour').sum()['Appliances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIiafxb9drin"
   },
   "outputs": [],
   "source": [
    "df_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UySF4HVAdspV"
   },
   "outputs": [],
   "source": [
    "# Line plot of hour vs Appliances(hour is on X-axis)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(df_hourly)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl-MZdwaH4Th"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4oe9y5jH4Lq"
   },
   "source": [
    "LinePlot is a plot from matplotlib library which helps in visualization the rate of increment or decrement of a value with respect to another value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3-rjv2vH4Co"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRMnLXXhID-v"
   },
   "source": [
    "##### From this line plot, the usage of appliances is a steady rise starting from 12 am and hits peak aroud 18th hour of the day. Then, after hitting its peak it takes a sudden dip starting from 21ist hour. The underlying reason might be because its night time and people probably will be less active."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc-ImOQ3d98q"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK61O1IoILZQ"
   },
   "source": [
    "The Energy is higher in certain hour of the day and it can fixed by being consicous about energy usage at that hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEwbjDeuILQI"
   },
   "source": [
    "## Chart - 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eu0xQ4sedyS_"
   },
   "outputs": [],
   "source": [
    "#Checking the unique values of the week column\n",
    "df['week'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeFS4GE6fS4s"
   },
   "source": [
    "***The data has been collected for 20 weeks starting from Jan 1 to May 27.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "np2DMGBheyZt"
   },
   "outputs": [],
   "source": [
    "##Creating another dataframe with respect to the week column's sum\n",
    "df_weekly = df.groupby('week').sum()['Appliances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYOJS9zxf1b6"
   },
   "outputs": [],
   "source": [
    "df_weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZn34FJ-f9gf"
   },
   "outputs": [],
   "source": [
    "#Bar plot which shows the usage of appliances in a week\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "df_weekly.plot(kind='bar', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3qU-pAPIc1t"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2G6AI_YIcqq"
   },
   "source": [
    "BarPlot is a plot from matplotlib library which is similar to the countplot and is used to distinguish two values effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP1tZJWCIceX"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L6LwDzvIk4R"
   },
   "source": [
    "##### This bar plot shows that at week 14 i.e, the second week of April, the usage of appliances is the highest and on the other hand, its lowest in the last week of the period i.e, the fourth week of May."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOofenPFgaWk"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izP6HX6uIvwr"
   },
   "source": [
    "The energy is scattered unevenly among all the weeks from Jan and May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYOe8HHYYhN8"
   },
   "outputs": [],
   "source": [
    "#Extracting the year from the date column\n",
    "year = []\n",
    "for i in range(len(df['date'])):\n",
    "  year.append(df['date'][i].year)\n",
    "df['year'] = year  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p45CIZ28gCsJ"
   },
   "outputs": [],
   "source": [
    "df1['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcnqA5NchT0-"
   },
   "source": [
    "# This data collection was collected in the year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDhVo5BXjLWZ"
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpJxGHl-jtQc"
   },
   "outputs": [],
   "source": [
    "# Dropping the month, week,year column as we are done with EDA\n",
    "df2.drop(columns = (['month', 'week', 'year']), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WVSUo9Uj7mE"
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6awbvc0XkCB-"
   },
   "source": [
    "***All columns are of desirable data type***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXH8MWZhIwo3"
   },
   "source": [
    "## Chart - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asecHsEv3Axk"
   },
   "outputs": [],
   "source": [
    "# Histogram of all the features to understand the distribution\n",
    "df2.hist(bins = 20 , figsize= (15,15 )) ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssn1lOI2JH7q"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4l4NgcCJHzo"
   },
   "source": [
    "Histogram is a plot from matplotlib library which really helps getting the distribution of values of a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2Q1MFtsJHoZ"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md3j1lr-JHiP"
   },
   "source": [
    "#####We have plotted the numeric features using histogram and we can see that except customer service calls, Total intl calls ,Number vmail messages, the features are normally distributed with little to no skewness. Thus the variables are as gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-bPzLHJJHbh"
   },
   "source": [
    "### 3. Will the gained insights help creating a positive business impact? \n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-aho91UJT73"
   },
   "source": [
    "No Business impact. Just to see that whether the distriution is skewed or of gaussian distributon or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_BQR96yJfXx"
   },
   "source": [
    "## Chart - 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JL5Sfh94NIY"
   },
   "outputs": [],
   "source": [
    "\n",
    "# obtaining correlation plots between dependent and independent variables\n",
    "\n",
    "numeric_features = df2.columns\n",
    "for col in numeric_features[1:]:\n",
    "  fig = plt.figure(figsize=(9, 6))\n",
    "  ax = fig.gca()\n",
    "  feature = df2[col]\n",
    "  label = df2['Appliances']\n",
    "  correlation = feature.corr(label)\n",
    "  plt.scatter(x=feature, y=label)\n",
    "  plt.xlabel(col)\n",
    "  plt.ylabel('Appliances')\n",
    "  ax.set_title('Appliances' + col + '- correlation: ' + str(correlation))\n",
    "  z = np.polyfit(df2[col], df2['Appliances'], 1)\n",
    "  y_hat = np.poly1d(z)(df2[col])\n",
    "\n",
    "  plt.plot(df2[col], y_hat, \"r--\", lw=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kooKjtEr0yRF"
   },
   "source": [
    "### This is the correlation of all the values of Dependent variable with Independent variable values and plotting the best fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVnq7Mv25QIm"
   },
   "outputs": [],
   "source": [
    "# function to calculate Multicollinearity\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lv5gvlwD5ReI"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GCFXqJu5aCS"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['rv2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNAa8Rtk57WY"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date' ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTGuqJGO6B3D"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['T1'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x4vzlqd8p8N"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Vi5o3Yg8rga"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['T9'],axis=1,inplace=True)\n",
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQHDVZqg8yyX"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['Press_mm_hg'],axis=1,inplace=True)\n",
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leYR-A9b84zV"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['RH_2', 'T2','RH_1', 'RH_4', 'RH_3','T7','T5'],axis=1,inplace=True)\n",
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrnWXIbY9c8j"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['T3', 'T4','RH_7', 'RH_8', 'RH_9','RH_out', 'T_out'],axis=1,inplace=True)\n",
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__9lVy8N90S2"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['RH_5', 'T6', 'T8',],axis=1,inplace=True)\n",
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date' ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yw1BAFX-JdS"
   },
   "outputs": [],
   "source": [
    "df2[df2.columns[:]].corr()['Appliances'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuiMe1tXDPKh"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns = (['hour_avg']), inplace =  True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m4QuW2MyXqQ"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns = (['date']), inplace =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcB7sqXgkus1"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date' ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5LvieMFt85d"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns = (['weekday_avg']), inplace =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCiDAsCguMOy"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date' ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuRZukiSVEVX"
   },
   "outputs": [],
   "source": [
    "df2.drop(columns = (['weekday']), inplace =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0Oc3e7QVHh4"
   },
   "outputs": [],
   "source": [
    "calc_vif(df2[[i for i in df2.describe().columns if i not in ['Appliances','date' ]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e0pCQhSb7e0"
   },
   "source": [
    "#The above column features are the ones which remained after removing multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fe-dlwD0rwd"
   },
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX1NCt94fTvx"
   },
   "outputs": [],
   "source": [
    "#Heatmap after reducing the multicollenearity \n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(df2.corr('pearson'),vmin=-1, vmax=1,cmap='coolwarm',annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9Oh585BJsNG"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glf7MAk1JsJZ"
   },
   "source": [
    "Correlation heatmap helps in getting the absolute correlation values of columns and their heatmap with intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDGv4yQsJsCZ"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75VLsWRAJ0qa"
   },
   "source": [
    "These two correlation plots represent the correlation before and after droppin the highly correlation variable in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig6DN6ysJ1x7"
   },
   "source": [
    "## Chart - 15 - Pair Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLGkOj4aJ59z"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue ='Appliances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AF3uXVrhJ6P4"
   },
   "source": [
    "### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGCZrBtpJ-FU"
   },
   "source": [
    "The Seaborn Pairplot allows us to plot pairwise relationships between variables within a dataset. This creates a nice visualisation and helps us understand the data by summarising a large amount of data in a single figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwNWjbdUJ-of"
   },
   "source": [
    "### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcLY_BkuKCK5"
   },
   "source": [
    "Pairplot helped us in visualizing the relationship among the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxb0lmOOOVVz"
   },
   "source": [
    "## *** Hypothesis Testing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wo1_YHVOVP3"
   },
   "source": [
    "# Hypothetical Statement - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1vhe0G3_7sO"
   },
   "source": [
    "# HYPOTHESIS : **Appliance usage on weekends is more than weekdays.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o06tAKLFOVM9"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_txlmb7OVJR"
   },
   "source": [
    "**Null Hypothesis** : No, Weekends have no effect on appliance usage.\n",
    "\n",
    "**Alternate Hypothesis** : Yes, Weekends do have an influence on appliance usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bim86JXDsx-u"
   },
   "source": [
    "### ***We assume siginificance level to be 0.05***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kg2RZrQOlOe"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3Snpo7fOqH-"
   },
   "outputs": [],
   "source": [
    "\n",
    "hypo_data = pd.crosstab(df1['Appliances'], df1['weekday'], margins=False)\n",
    "hypo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfWOD9_0tBgp"
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(hypo_data)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXVDaHJUtag4"
   },
   "source": [
    "### ***The p value is smaller than significance level , we will reject the null hypothesis and accept the alternative hypothesis.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq6UE4z-OlLV"
   },
   "source": [
    "#### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFudc_FxOlId"
   },
   "source": [
    "We used Chi Square contingency to test the P value for the Hypthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22PuvRxCO2_Y"
   },
   "source": [
    "#### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY5_pDZ0O22B"
   },
   "source": [
    "The Chi Square contingency provides a foundation for statistical inference, where statistical tests question the relationship between the variables on the basis of the data observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TjB_h0qO6wn"
   },
   "source": [
    "# Hypothetical Statement - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR8uM6RBwehZ"
   },
   "source": [
    "# HYPOTHESIS : **Energy usage by Appliances is not Equal across all the months.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dndB_67RO6tK"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FK3bB5eVwiiB"
   },
   "source": [
    "**Null Hypothesis** : No, the Energy usage by appliances is equal across all the months. \n",
    "\n",
    "**Alternate Hypothesis** : Yes, the Energy usage by appliances is equal across all the months. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdWSF2h4xZYb"
   },
   "source": [
    "### ***We assume siginificance level to be 0.05***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wrf5xeRO6qL"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzwC8A21PB1g"
   },
   "outputs": [],
   "source": [
    "hypo_data = pd.crosstab(df1['Appliances'], df1['month'], margins=False)\n",
    "hypo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XL40cym5wVh6"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2_contingency\n",
    "stat, p, dof, expected = chi2_contingency(hypo_data)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT8iuV1IxfDw"
   },
   "source": [
    "### ***The p value is smaller than significance level , we will reject the null hypothesis and accept the alternative hypothesis.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKWUvXEOO6lw"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyiPb_nVO6U7"
   },
   "source": [
    "We used Chi Square contingency to test the P value for the Hypthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POTyWivIO6iY"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLm_uBiJPLyn"
   },
   "source": [
    "The Chi Square contingency provides a foundation for statistical inference, where statistical tests question the relationship between the variables on the basis of the data observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0deE-gWPrH0"
   },
   "source": [
    "## *** Feature Engineering & Data Pre-processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXnL4RFAlNFc"
   },
   "source": [
    "###  Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3AKca6alOad"
   },
   "source": [
    "There weren't any missing or null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75yLHKCklO4D"
   },
   "source": [
    "###  Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIWya1mdEitb"
   },
   "outputs": [],
   "source": [
    "# df1 = df.copy()\n",
    "# # Find outliers\n",
    "# sorted_appliances = df1.sort_values('Appliances',ascending=False)\n",
    "# print(\"The number of the 0,1% top values of appliances' load is\",\n",
    "#       len(sorted_appliances.head(len(sorted_appliances)//1000)),\"and they have power load higher than\",\n",
    "#       sorted_appliances.Appliances[19], \"Wh.\")\n",
    "\n",
    "# # boxplot appliances\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# ax = sns.boxplot(sorted_appliances.Appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kW1vmMCtBOxG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Outliers removal\n",
    "\n",
    "# df1 = df.dropna()\n",
    "# df1 = df.drop(df[(df.Appliances>140)|(df.Appliances<0)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyYBoOu2x9GM"
   },
   "source": [
    "### ***The following codes have been already executed in the notebook and have been used for plotting charts.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JTx5XuylWl-"
   },
   "source": [
    "### What all outlier treatment techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5uFGFZPlcrY"
   },
   "source": [
    "Used the boxplot to check the outliers and capped the values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "621yDleelc_Z"
   },
   "source": [
    "###  Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1aoom5_ldZd"
   },
   "source": [
    "No categorical Columns in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG49L9B6lhga"
   },
   "source": [
    "###  Feature Manipulation & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7hhjprFCKDk"
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkoGCayQlsvt"
   },
   "source": [
    "###  Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtbU4O4kl00g"
   },
   "source": [
    "### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zn0O-W2Zl33e"
   },
   "source": [
    "No in our case the data doesn't need to be transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq16LpB2mCSJ"
   },
   "source": [
    "###  Dimesionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DrP6HBhmK1A"
   },
   "source": [
    "### Do you think that dimensionality reduction is needed? Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reGTH4fqmGbc"
   },
   "source": [
    "In our case, Dimesionality Reduction isn't used because the variables are fairly less in number and is of desired dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvOfKjSkmPO-"
   },
   "source": [
    "###  Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPdWDMLEDXrl"
   },
   "outputs": [],
   "source": [
    "# Creating the data of independent variables\n",
    "Y = df2['Appliances']\n",
    "\n",
    "# Create the dependent variable data\n",
    "X = df2.drop(columns=['Appliances'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bVztcoPGhks"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP_LqvhRBrJo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgSs9IMUB6OI"
   },
   "source": [
    "### What data splitting ratio have you used and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1fuODe8n2T0"
   },
   "source": [
    "We allocated 80% of data to train the model and the remaining 20% for test the peformance of the model. 80-20 is ideal because it gives equal emphasis technically to both test and train datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2QHUdSRl4SE"
   },
   "source": [
    "###  Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Nlfp5IMGqrd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Transforming data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTk4RWQcmA1z"
   },
   "source": [
    "### Which method have you used to scale you data and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8omN0W-mBt-"
   },
   "source": [
    "MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pfxD0h5oAsH"
   },
   "source": [
    "###  Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jynuvwmQoB3w"
   },
   "source": [
    "### Do you think the dataset is imbalanced? Explain Why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMuih5OuoCT_"
   },
   "source": [
    "No, the data isn't imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i35O1DhGoR3e"
   },
   "source": [
    "## *** ML Model Implementation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wemkSmzPX7q7"
   },
   "source": [
    "#Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHGcSn1WGsll"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGWNvHPvG2y5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predicting the Train set results\n",
    "\n",
    "Y_pred_train = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaPnH7ElHWur"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predicting the Test set results\n",
    "\n",
    "Y_pred_test = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKb0D23vHYeR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# r2 score of train set\n",
    "\n",
    "r2_linear_train = r2_score(Y_train, Y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYiU08x1HaZe"
   },
   "outputs": [],
   "source": [
    "\n",
    "r2_linear_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzTnzaw1HfhO"
   },
   "outputs": [],
   "source": [
    "\n",
    "r2_linear_test = r2_score(Y_test, Y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnqoxNxXHixy"
   },
   "outputs": [],
   "source": [
    "r2_linear_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvJEGHiuHmba"
   },
   "outputs": [],
   "source": [
    "\n",
    "# different metrics used\n",
    "\n",
    "MSE  = mean_squared_error(Y_test,Y_pred_test)\n",
    "print(\"MSE :\" , MSE)\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"RMSE :\" ,RMSE)\n",
    "\n",
    "r2_linear_test = r2_score(Y_test,Y_pred_test)\n",
    "print(\"R2 :\" ,r2_linear_test)\n",
    "print(\"Adjusted R2 : \",1-(1-r2_score(Y_test,Y_pred_test))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdhY7Tx1oWet"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ6jkeZzGv1x"
   },
   "source": [
    "The R2 Score of the Linear Regression model 32% is not good, we should more models to get a performance gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRe0TwpCYGtS"
   },
   "source": [
    "#Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SFpFevUbmHJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso  = Lasso(alpha=0.001 , max_iter= 3000)\n",
    "\n",
    "lasso.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAHJuxStbv4K"
   },
   "outputs": [],
   "source": [
    "lasso =  lasso.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdIWFn67oxpb"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ef4rV1-ZbxyA"
   },
   "outputs": [],
   "source": [
    "### Cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso = Lasso()\n",
    "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]}\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79xBl1sjdHc3"
   },
   "outputs": [],
   "source": [
    "# getting best parameters\n",
    "\n",
    "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
    "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVvJCZBFdP-E"
   },
   "outputs": [],
   "source": [
    "\n",
    "lasso  = Lasso(alpha=0.01 , max_iter= 3000)\n",
    "\n",
    "lasso.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4hoO2eBdVyH"
   },
   "outputs": [],
   "source": [
    "Lasso =lasso.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYJSsUyMInps"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zviA98cMIoxz"
   },
   "source": [
    "The R2 Score of the Linear Regression model 31% is not good, we should more models to get a performance gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF6hXqXrox8d"
   },
   "source": [
    "### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyQiX286oyWv"
   },
   "source": [
    "We used GridSearchCV for cross validation and to tune and optimize the hyperparameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64h5_cIpoz9p"
   },
   "source": [
    "### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9w2Qh4xoz6i"
   },
   "source": [
    "No we didn't see any improvements after cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi5YUzjPoz3C"
   },
   "source": [
    "### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZAimgCPozzt"
   },
   "source": [
    "The R2 score is a very important metric that is used to evaluate the performance of a regression-based machine learning model. It is pronounced as R squared and is also known as the coefficient of determination. It works by measuring the amount of variance in the predictions explained by the dataset.\n",
    "\n",
    "The Mean Squared Error measures how close a regression line is to a set of data points. It is a risk function corresponding to the expected value of the squared error loss. Mean square error is calculated by taking the average, specifically the mean, of errors squared from data as it relates to a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TEj6uYcYL4K"
   },
   "source": [
    "#Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRkAf-gAdmJl"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "ridge_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hlZfvWsdr2Q"
   },
   "outputs": [],
   "source": [
    "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
    "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3BvYEhOozmg"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_I-Rrl5IgoF"
   },
   "source": [
    "The R2 Score of the Linear Regression model 31% is not good, we should more models to get a performance gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQcxkzh8qWIX"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd8i-aycdwrC"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge  = Ridge(alpha=1 , max_iter= 3000)\n",
    "\n",
    "ridge.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGedN8-leXBa"
   },
   "outputs": [],
   "source": [
    "ridge = ridge.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-zTK6iPqWLi"
   },
   "source": [
    "### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXZr1DY_qV4P"
   },
   "source": [
    "We used GridSearchCV for cross validation and to tune and optimize the hyperparameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahLTwb0pqV1G"
   },
   "source": [
    "### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhqW9ZKWqVxt"
   },
   "source": [
    "No we didn't see any improvements after cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JffJiJvuZkfz"
   },
   "source": [
    "#Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXJgAlXqe40C"
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree = DecisionTreeRegressor()\n",
    "\n",
    "param = {'max_depth' : [1,4,5,6,7,10,15,20,8]}\n",
    "\n",
    "gridSearch_decisionTree=GridSearchCV(decisionTree,param,scoring='r2',cv=6)\n",
    "gridSearch_decisionTree.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "best_DecisionTree=gridSearch_decisionTree.best_estimator_\n",
    "bestDecisionTree_testScore=best_DecisionTree.score(X_test,Y_test)\n",
    "r2_decision_test = best_DecisionTree.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UadyNzxfD69"
   },
   "outputs": [],
   "source": [
    "\n",
    "# extracting best parameters\n",
    "\n",
    "print(f\"The best Decision Tree R2 score is {gridSearch_decisionTree.best_score_} with max depth {gridSearch_decisionTree.best_params_['max_depth']}\")\n",
    "print('\\n')\n",
    "print(f\"The best R2 test score is : {bestDecisionTree_testScore} with max depth = {gridSearch_decisionTree.best_params_['max_depth']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQraj0FWFzWU"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if6yx9PNFija"
   },
   "source": [
    "The R2-score is close to 73% and its fair but not good enough. We want a model which is above 75% and around 80-85% which is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VyNC8KQZZ9U"
   },
   "source": [
    "#Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jsjm1W9XfIUg"
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForestAlgo = RandomForestRegressor()\n",
    "\n",
    "\n",
    "param = {'n_estimators' : [int(x) for x in np.linspace(start=10,stop=20, num=5)], \n",
    "         'max_depth' : [10,15,20],\n",
    "         'min_samples_split':[2,4],\n",
    "         'min_samples_leaf':[1,2],\n",
    "         'bootstrap' : [True,False]\n",
    "        }\n",
    "\n",
    "gridSearch_RandomForest=GridSearchCV(randomForestAlgo,param,scoring='r2',cv=5)\n",
    "gridSearch_RandomForest.fit(X_train,Y_train)\n",
    "\n",
    "best_randomForest=gridSearch_RandomForest.best_estimator_\n",
    "bestRandomForest_testScore=best_randomForest.score(X_test,Y_test)\n",
    "r2_randomforest_test = best_randomForest.score(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGxpvaY7fNSt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# getting best parameters\n",
    "\n",
    "print(f\"The best Random Forest R2 train score is : {gridSearch_RandomForest.best_score_} with n estimators = {gridSearch_RandomForest.best_params_['n_estimators']}, max depth : {gridSearch_RandomForest.best_params_['max_depth']}, min samples split : {gridSearch_RandomForest.best_params_['min_samples_split']} and min samples leaf : {gridSearch_RandomForest.best_params_['min_samples_leaf']}\")\n",
    "print('\\n')\n",
    "print(f\"The best Random Forest R2 test score is : {bestRandomForest_testScore} with n estimators = {gridSearch_RandomForest.best_params_['n_estimators']}, max depth : {gridSearch_RandomForest.best_params_['max_depth']}, min samples split : {gridSearch_RandomForest.best_params_['min_samples_split']} and min samples leaf : {gridSearch_RandomForest.best_params_['min_samples_leaf']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTnLirDoF9SB"
   },
   "source": [
    "###1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCAKWoS1GRSk"
   },
   "source": [
    "The R2-score is really good that is  79%. We are really close to 80%, we can implement more models to get that one 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HeFP1OlZtqg"
   },
   "source": [
    "#Extra Trees Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWzTERp7hkYo"
   },
   "outputs": [],
   "source": [
    "# training model\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "extraTreesAlgo = ExtraTreesRegressor()\n",
    "\n",
    "param = {'n_estimators' : [int(x) for x in np.linspace(start=10,stop=20, num=5)], \n",
    "         'max_depth' : [50,80,100],\n",
    "         'min_samples_split':[1,4,8],\n",
    "         'min_samples_leaf':[1,2,3],\n",
    "         'bootstrap' : [True,False]\n",
    "        }\n",
    "\n",
    "gridSearch_ExtraTrees=GridSearchCV(extraTreesAlgo,param,scoring='r2',cv=5)\n",
    "gridSearch_ExtraTrees.fit(X_train,Y_train)\n",
    "\n",
    "best_ExtrasTrees=gridSearch_ExtraTrees.best_estimator_\n",
    "bestExtrasTrees_testScore=best_ExtrasTrees.score(X_test,Y_test)\n",
    "r2_extratree_test = best_ExtrasTrees.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24gUuH1zhpxE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# getting best parameters\n",
    "\n",
    "print(f\"The best Extra Trees R2 score is : {gridSearch_ExtraTrees.best_score_} with n estimators = {gridSearch_ExtraTrees.best_params_['n_estimators']}, max depth : {gridSearch_ExtraTrees.best_params_['max_depth']}, min samples split : {gridSearch_ExtraTrees.best_params_['min_samples_split']} and min samples leaf : {gridSearch_ExtraTrees.best_params_['min_samples_leaf']}\")\n",
    "print('\\n')\n",
    "print(f\"The best Extra Trees R2 test score is : {bestExtrasTrees_testScore} with n estimators = {gridSearch_ExtraTrees.best_params_['n_estimators']}, max depth : {gridSearch_ExtraTrees.best_params_['max_depth']}, min samples split : {gridSearch_ExtraTrees.best_params_['min_samples_split']} and min samples leaf : {gridSearch_ExtraTrees.best_params_['min_samples_leaf']}\")\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ikm9vxSF_tF"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fy9iDTKGP5a"
   },
   "source": [
    "The R2-score is the best that is  80%. We have reached 80% accuracy which is really ideal for Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuMYolNgasJl"
   },
   "source": [
    "#XGBoost Regresion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCmu2BoWv9mv"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "xgb_grid.fit(X_train,\n",
    "         Y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n",
    "r2_XGBoost_test = xgb_grid.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8LJic8BGNiJ"
   },
   "source": [
    "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kc72OxwjGOwM"
   },
   "source": [
    "The R2-score is really good that is  76%. We passed the 75% mark but we can implement more models to get 80% model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUni0MMGifsG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# creating a list of all model names\n",
    "model_list = ['Linear Regression','Lasso Regression','Ridge Regression','Decision Tree Regressor','Random Forest Regressor','Extra Trees Regressor', 'XGBoost Regressor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8Ya0dcgvPWY"
   },
   "outputs": [],
   "source": [
    "\n",
    "# creating a list of all model r2 score results from above\n",
    "\n",
    "result_list = [r2_linear_test,Lasso,ridge,r2_decision_test,r2_randomforest_test,r2_extratree_test, r2_XGBoost_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjAHTnx_vVua"
   },
   "outputs": [],
   "source": [
    "\n",
    "# creating an empty dataframe\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZswAOG-vtx4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# adding above lists to the empty dataframe\n",
    "\n",
    "results_df['model name'] = model_list\n",
    "results_df['R2-score'] = result_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-swpvSF1vytg"
   },
   "outputs": [],
   "source": [
    "# dataframe containing results from all the above models used\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK22q2ctqVua"
   },
   "source": [
    "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1NomC2UGbaL"
   },
   "source": [
    "The R2 score is a very important metric that is used to evaluate the performance of a regression-based machine learning model. It is pronounced as R squared and is also known as the coefficient of determination. It works by measuring the amount of variance in the predictions explained by the dataset. Simply put, it is the difference between the samples in the dataset and the predictions made by the model.\n",
    "\n",
    "By accurately and precisely predicting the usage of Appliance Energy in a household, we can take appropriate measures to control it and preserve energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wfbaCxlGbz7"
   },
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETniIWBaGg0M"
   },
   "source": [
    "The Extra trees regression model is the best one with an R2 score of 80% and it can really help in solving this regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2-mvsQ2Gfm0"
   },
   "source": [
    "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ_vby5-nPcG"
   },
   "source": [
    "###Implement Explain Like Iam 5 Model Explainability Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxrExbY9itX-"
   },
   "outputs": [],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlyfYAwYkMtj"
   },
   "outputs": [],
   "source": [
    "import eli5 as eli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWbClKIAorf7"
   },
   "outputs": [],
   "source": [
    "features = list(df2.columns)\n",
    "features.remove('Appliances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSDotsX0kMpV"
   },
   "outputs": [],
   "source": [
    "# Weights for Extra Trees\n",
    "eli.explain_weights(best_ExtrasTrees, feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ukK-aQVGgWI"
   },
   "source": [
    "As we can see from ELI5, the 'hour' feature holds the most weight against all the other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhJEjazarU9s"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaH8DEsB4Jyf"
   },
   "source": [
    "#Conclusion from EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn2UIrtY4NaQ"
   },
   "source": [
    "● On average, the household energy appliances usage was at its peak during the 18th hour of the day.\n",
    "\n",
    "● The warmest temperatures are the laundry room(T3), teenager room(T8) and kitchen area(T1) respectively. And the coldest rooms are bathroom(T5) and parents room(T9) \n",
    "\n",
    "● The energy usage stays consistent from temperatures 5° to 25°. At extreme high and low temperatures, the energy usage is relatively low \n",
    "\n",
    "● There is little to no correlation between pressure and energy consumption \n",
    "\n",
    "● The humidity is at its highest outside the building(RH_out) and lowest in the ironing room(RH_7) \n",
    "\n",
    "● In Feb, Mar, April, the usage of appliances is more or less equal and that of Jan was the lowest one \n",
    "\n",
    "● At week 14 i.e, the second week of April, the usage of appliances is the highest and on the other hand, its lowest in the last week of the period i.e, the fourth week of May"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRzCUq3NMAKL"
   },
   "source": [
    "# Conclusion from Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08XMAkYsMCzX"
   },
   "source": [
    "1.From the above results dataframe, the Extra Tres Regressor model is the best model with accuracy of 80% for this dataset.\n",
    "\n",
    "2.Decision Tree Regressor had an accuracy of less than 73% which is not desirable.\n",
    "\n",
    "3.Feature Engineering really helped us reach this accuracy.\n",
    "\n",
    "4.We have extracted sensible and appropriate information using Exploratory Data Analysis."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ZeeshanAhmed95/Capstone-Data-Application-linear-regression/blob/main/Zeeshan_Capstone_Project_2_Appliance_Energy_Prediction.ipynb",
     "timestamp": 1679646993052
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
